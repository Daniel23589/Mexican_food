{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5960030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "print(os.listdir(\"MAFood121\"))\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "torch.manual_seed(42) # try and make the results more reproducible\n",
    "BASE_PATH = 'MAFood121'\n",
    "\n",
    "epochs = 35\n",
    "batch_size = 64\n",
    "MICRO_DATA = True # very small subset (just 3 groups)\n",
    "SAMPLE_TRAINING = False # make train set smaller for faster iteration\n",
    "IMG_SIZE = (384, 384) # Try to change the model to U-net to avoid the resizing\n",
    "\n",
    "#Classes of dishes\n",
    "f = open(BASE_PATH + '/annotations/dishes.txt', \"r\")\n",
    "classes = f.read().strip().split('\\n')\n",
    "f.close()\n",
    "#print(\"***** classes = dishes.txt: ***** \" + str(classes))\n",
    "#print(\"#######################################################################################\")\n",
    "\n",
    "#Ingredients for each class\n",
    "f = open(BASE_PATH + '/annotations/foodgroups.txt', \"r\")\n",
    "ingredients = f.read().strip().split('\\n')\n",
    "f.close()\n",
    "#print(\"***** ingredients = foodgroups.txt: ***** \" + str(ingredients))\n",
    "#print(\"#######################################################################################\")\n",
    "\n",
    "#Base Ingredients\n",
    "f = open(BASE_PATH + '/annotations/baseIngredients.txt', \"r\")\n",
    "base_ing = f.read().strip().split(', ')\n",
    "f.close()\n",
    "#print(\"***** base_ing = baseIngredients.txt: ***** \" + str(base_ing))\n",
    "#print(\"#######################################################################################\")\n",
    "\n",
    "#Recovery of annotations ML\n",
    "#train\n",
    "f = open(BASE_PATH + '/annotations/train.txt', \"r\")\n",
    "train_images = f.read().split('\\n')\n",
    "f.close()\n",
    "f = open(BASE_PATH + '/annotations/train_lbls_ff.txt', \"r\")\n",
    "train_labels = f.read().split('\\n')\n",
    "f.close()\n",
    "\n",
    "#val\n",
    "f = open(BASE_PATH + '/annotations/val.txt', \"r\")\n",
    "val_images = f.read().split('\\n')\n",
    "f.close()\n",
    "f = open(BASE_PATH + '/annotations/val_lbls_ff.txt', \"r\")\n",
    "val_labels = f.read().split('\\n')\n",
    "f.close()\n",
    "\n",
    "#test\n",
    "f = open(BASE_PATH + '/annotations/test.txt', \"r\")\n",
    "test_images = f.read().split('\\n')\n",
    "f.close()\n",
    "f = open(BASE_PATH + '/annotations/test_lbls_ff.txt', \"r\")\n",
    "test_labels = f.read().split('\\n')\n",
    "f.close()\n",
    "\n",
    "#Recovery of annotations SL\n",
    "#train\n",
    "f = open(BASE_PATH + '/annotations/train.txt', \"r\")\n",
    "train_imagessl = f.read().split('\\n')\n",
    "f.close()\n",
    "f = open(BASE_PATH + '/annotations/train_lbls_d.txt', \"r\")\n",
    "train_labelssl = f.read().split('\\n')\n",
    "f.close()\n",
    "\n",
    "#val\n",
    "f = open(BASE_PATH + '/annotations/val.txt', \"r\")\n",
    "val_imagessl = f.read().split('\\n')\n",
    "f.close()\n",
    "f = open(BASE_PATH + '/annotations/val_lbls_d.txt', \"r\")\n",
    "val_labelssl = f.read().split('\\n')\n",
    "f.close()\n",
    "\n",
    "#test\n",
    "f = open(BASE_PATH + '/annotations/test.txt', \"r\")\n",
    "test_imagessl = f.read().split('\\n')\n",
    "f.close()\n",
    "f = open(BASE_PATH + '/annotations/test_lbls_d.txt', \"r\")\n",
    "test_labelssl = f.read().split('\\n')\n",
    "f.close()\n",
    "\n",
    "# Multi-label\n",
    "train_images_ml = [BASE_PATH+\"/images/\" + s for s in train_images]\n",
    "train_df_ml = pd.DataFrame({'path': train_images_ml, 'ml_class_id': train_labels})\n",
    "\n",
    "val_images_ml = [BASE_PATH+\"/images/\" + s for s in val_images]\n",
    "val_df_ml = pd.DataFrame({'path': val_images_ml, 'ml_class_id': val_labels})\n",
    "\n",
    "test_images_ml = [BASE_PATH+\"/images/\" + s for s in test_images]\n",
    "test_df_ml = pd.DataFrame({'path': test_images_ml, 'ml_class_id': test_labels})\n",
    "\n",
    "# Single-Label\n",
    "train_images_sl = [BASE_PATH+\"/images/\" + s for s in train_imagessl]\n",
    "train_df_sl = pd.DataFrame({'path': train_images_sl, 'sl_class_id': train_labelssl})\n",
    "\n",
    "val_images_sl = [BASE_PATH+\"/images/\" + s for s in val_imagessl]\n",
    "val_df_sl = pd.DataFrame({'path': val_images_sl, 'sl_class_id': val_labelssl})\n",
    "\n",
    "test_images_sl = [BASE_PATH+\"/images/\" + s for s in test_imagessl]\n",
    "test_df_sl = pd.DataFrame({'path': test_images_sl, 'sl_class_id': test_labelssl})\n",
    "\n",
    "train_df_ml = train_df_ml[:-1]\n",
    "val_df_ml = val_df_ml[:-1]\n",
    "test_df_ml = test_df_ml[:-1]\n",
    "\n",
    "train_df_ml['class_name'] = train_df_ml['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
    "#print(train_df_ml)\n",
    "#print(\"-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "val_df_ml['class_name'] = val_df_ml['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
    "#print(val_df_ml)\n",
    "#print(\"-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "test_df_ml['class_name'] = test_df_ml['path'].map(lambda x: os.path.split(os.path.dirname(x))[-1])\n",
    "#print(test_df_ml)\n",
    "#print(\"-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "import glob\n",
    "#Recovery of annotations ML\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "#Dataframe for train\n",
    "train_ingredients = []\n",
    "train_classid = []\n",
    "# Load train_lbls_ff.txt here\n",
    "for file_path in glob.glob(BASE_PATH + '/annotations/train_lbls_ff.txt'):\n",
    "    with open(file_path) as f1:\n",
    "        for line in f1:\n",
    "            idx_ingredients = []\n",
    "            classid = int(line)\n",
    "            train_classid.append(classid)\n",
    "            for ing in ingredients[classid].strip().split(\",\"):\n",
    "                idx_ingredients.append(str(base_ing.index(ing)))\n",
    "            train_ingredients.append(idx_ingredients)\n",
    "\n",
    "df_train = pd.DataFrame(mlb.fit_transform(train_ingredients), columns=mlb.classes_) #binary encode ingredients\n",
    "df_train[\"path\"] = train_df_ml['path'] #train_img_df['path']\n",
    "df_train[\"ml_class_id\"] = train_classid\n",
    "food_dict_train = df_train\n",
    "\n",
    "#Dataframe for train images\n",
    "new_data = []\n",
    "for index, row in train_df_ml.iterrows():\n",
    "    #food = row[\"class_name\"]\n",
    "    path = row[\"path\"]\n",
    "    class_id = row[\"ml_class_id\"]\n",
    "\n",
    "    binary_encod = food_dict_train.loc[food_dict_train[\"path\"] == path]\n",
    "    new_data.append(np.array(binary_encod)[0])\n",
    "\n",
    "col_names = list(binary_encod.columns.values)\n",
    "train_df = pd.DataFrame(new_data, columns = col_names)\n",
    "\n",
    "# Dataframe for val\n",
    "val_ingredients = []\n",
    "val_classid = []\n",
    "# Load val_lbls_ff.txt here\n",
    "for file_path in glob.glob(BASE_PATH + '/annotations/val_lbls_ff.txt'):\n",
    "    with open(file_path) as f1:\n",
    "        for line in f1:\n",
    "            idx_ingredients = []\n",
    "            classid = int(line)\n",
    "            val_classid.append(classid)\n",
    "            for ing in ingredients[classid].strip().split(\",\"):\n",
    "                idx_ingredients.append(str(base_ing.index(ing)))\n",
    "            val_ingredients.append(idx_ingredients)\n",
    "\n",
    "# Use the same mlb object for val\n",
    "val_df = pd.DataFrame(mlb.transform(val_ingredients), columns=mlb.classes_) # binary encode ingredients\n",
    "val_df[\"path\"] = val_df_ml['path']\n",
    "val_df[\"ml_class_id\"] = val_classid\n",
    "food_dict_val = val_df  # Change this to use val_df\n",
    "\n",
    "# Dataframe for val images\n",
    "val_data = []\n",
    "for index, row in val_df_ml.iterrows():\n",
    "    path = row[\"path\"]\n",
    "    class_id = row[\"ml_class_id\"]\n",
    "\n",
    "    binary_encod = food_dict_val.loc[food_dict_val[\"path\"] == path]\n",
    "    val_data.append(np.array(binary_encod)[0])\n",
    "\n",
    "col_names = list(binary_encod.columns.values)\n",
    "val_df = pd.DataFrame(val_data, columns=col_names)\n",
    "\n",
    "# Dataframe for test\n",
    "test_ingredients = []\n",
    "test_classid = []\n",
    "# busca ambos archivos en el directorio de anotaciones\n",
    "for file_path in glob.glob(BASE_PATH + '/annotations/test_lbls_ff.txt'):\n",
    "    with open(file_path) as f1:\n",
    "        for line in f1:\n",
    "            idx_ingredients = []\n",
    "            classid = int(line)\n",
    "            test_classid.append(classid)\n",
    "            for ing in ingredients[classid].strip().split(\",\"):\n",
    "                idx_ingredients.append(str(base_ing.index(ing)))\n",
    "            test_ingredients.append(idx_ingredients)\n",
    "\n",
    "# Use the same mlb object for test\n",
    "df_test = pd.DataFrame(mlb.transform(test_ingredients), columns=mlb.classes_) # binary encode ingredients\n",
    "df_test[\"path\"] = test_df_ml['path']\n",
    "df_test[\"ml_class_id\"] = test_classid\n",
    "food_dict_test = df_test  # Change this to use df_test\n",
    "\n",
    "# Dataframe for test images\n",
    "test_data = []\n",
    "for index, row in test_df_ml.iterrows():\n",
    "    path = row[\"path\"]\n",
    "    class_id = row[\"ml_class_id\"]\n",
    "\n",
    "    binary_encod = food_dict_test.loc[food_dict_test[\"path\"] == path]\n",
    "    test_data.append(np.array(binary_encod)[0])\n",
    "\n",
    "col_names = list(binary_encod.columns.values)\n",
    "test_df = pd.DataFrame(test_data, columns=col_names)\n",
    "\n",
    "train_df = train_df.merge(train_df_sl, left_on='path', right_on='path')\n",
    "val_df = val_df.merge(val_df_sl, left_on='path', right_on='path')\n",
    "test_df = test_df.merge(test_df_sl, left_on='path', right_on='path')\n",
    "\n",
    "train_df.to_hdf('train_df.h5', 'df', mode='w', format='table', data_columns=True)\n",
    "val_df.to_hdf('val_df.h5', 'df', mode='w', format='table', data_columns=True)\n",
    "test_df.to_hdf('test_df.h5', 'df', mode='w', format='table', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb6376a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>path</th>\n",
       "      <th>ml_class_id</th>\n",
       "      <th>sl_class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MAFood121/images/tostadas/65_2.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MAFood121/images/guacamole/2264147.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MAFood121/images/caesar_salad/3407801.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MAFood121/images/tostadas/32_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MAFood121/images/nachos/217585.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MAFood121/images/chicken_quesadilla/1362306.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MAFood121/images/pozole/20_1.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MAFood121/images/nachos/2649179.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MAFood121/images/tacos/304636.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MAFood121/images/nachos/2206816.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7  8  \\\n",
       "0    1  1  0  0  0  0  0  0  1   \n",
       "1    1  0  0  0  0  0  0  0  1   \n",
       "2    1  0  0  0  0  0  0  0  1   \n",
       "3    1  0  0  1  0  0  0  0  1   \n",
       "4    1  0  0  0  0  0  0  0  1   \n",
       "..  .. .. .. .. .. .. .. .. ..   \n",
       "273  1  0  0  0  0  0  0  0  1   \n",
       "274  0  0  0  0  0  0  0  1  1   \n",
       "275  1  0  0  0  0  0  0  0  1   \n",
       "276  1  0  0  0  0  0  0  0  1   \n",
       "277  1  0  0  0  0  0  0  0  0   \n",
       "\n",
       "                                                path  ml_class_id sl_class_id  \n",
       "0                 MAFood121/images/tostadas/65_2.jpg            9          10  \n",
       "1             MAFood121/images/guacamole/2264147.jpg            5           5  \n",
       "2          MAFood121/images/caesar_salad/3407801.jpg            5           0  \n",
       "3                 MAFood121/images/tostadas/32_1.jpg            0          10  \n",
       "4                 MAFood121/images/nachos/217585.jpg            5           7  \n",
       "..                                               ...          ...         ...  \n",
       "273  MAFood121/images/chicken_quesadilla/1362306.jpg            5           1  \n",
       "274                 MAFood121/images/pozole/20_1.jpg            7           8  \n",
       "275              MAFood121/images/nachos/2649179.jpg            5           7  \n",
       "276                MAFood121/images/tacos/304636.jpg            5           9  \n",
       "277              MAFood121/images/nachos/2206816.jpg            4           7  \n",
       "\n",
       "[278 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e8c675",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# metrics loss and accuracy\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "SMALL_DATA = False\n",
    "IMG_SIZE = (384, 384)\n",
    "\n",
    "# Load data from .h5 files\n",
    "train_df = pd.read_hdf('train_df.h5')\n",
    "val_df = pd.read_hdf('val_df.h5')\n",
    "test_df = pd.read_hdf('test_df.h5')\n",
    "\n",
    "if SMALL_DATA:\n",
    "    train_df = train_df[:128]\n",
    "    val_df = test_df[:128]\n",
    "    test_df = test_df[:128]\n",
    "\n",
    "col_names = list(train_df.columns.values)\n",
    "ing_names = col_names[:-3]\n",
    "targets = ing_names\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.iloc[idx]['path']\n",
    "        try:\n",
    "            image = cv2.imread(image_path, 1)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to read image at {image_path}\")\n",
    "            if image.shape[0] == 0 or image.shape[1] == 0:\n",
    "                raise ValueError(f\"Invalid image size for {image_path}\")\n",
    "\n",
    "            x = cv2.resize(image, IMG_SIZE)\n",
    "            x = torch.from_numpy(x.transpose(2, 0, 1)).float()\n",
    "\n",
    "#            sl_class_id = int(self.df.iloc[idx]['sl_class_id'])\n",
    "#            sl_onehot = np.array(sl_class_id)\n",
    "#            sl_onehot = (np.arange(len(classes)) == sl_onehot).astype(np.float32)\n",
    "#            sl_y = torch.from_numpy(sl_onehot)\n",
    "\n",
    "            ml_y = []\n",
    "            for i in range(len(base_ing)):\n",
    "                ml_y.append(self.df.iloc[idx][str(i)])\n",
    "            ml_y = np.array(ml_y, dtype=np.float32)\n",
    "\n",
    "            return (x, ml_y)  # return (x, sl_y, ml_y)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading image at {image_path}: {str(e)}\")\n",
    "            # Devuelve un valor predeterminado o imagen vacía\n",
    "            x = torch.zeros((3, IMG_SIZE[0], IMG_SIZE[1])).float()\n",
    "#            sl_y = torch.zeros(len(classes)).float()\n",
    "            ml_y = np.zeros(len(base_ing), dtype=np.float32)\n",
    "            return (x, ml_y) # return (x, sl_y, ml_y)\n",
    "\n",
    "# Create DataLoader objects for training, validation, and testing sets\n",
    "train_dataset = CustomDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(val_df)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = CustomDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# ResNet50 Model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "# Disable grad for all conv layers\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add two heads\n",
    "resnet.last_linear = resnet.fc\n",
    "n_features = resnet.fc.out_features\n",
    "#head_sl = nn.Sequential(\n",
    "#    nn.Linear(n_features, 512),\n",
    "#    nn.ReLU(inplace=True),\n",
    "#    nn.Dropout(p=0.2),\n",
    "#    nn.Linear(512, len(classes))\n",
    "#)\n",
    "head_ml = nn.Sequential(\n",
    "    nn.Linear(n_features, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, len(base_ing)),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Connect two heads\n",
    "class FoodModel(nn.Module):\n",
    "    def __init__(self, base_model, head_ml): # def __init__(self, base_model, head_sl, head_ml):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "#        self.head_sl = head_sl\n",
    "        self.head_ml = head_ml\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "#        sl = self.head_sl(x)\n",
    "        ml = self.head_ml(x)\n",
    "        return ml # return sl, ml\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FoodModel(resnet, head_ml) # model = FoodModel(resnet, head_sl, head_ml)\n",
    "model.to(device)\n",
    "\n",
    "# Define Loss\n",
    "#sl_loss_fn = nn.CrossEntropyLoss()\n",
    "ml_loss_fn = nn.BCELoss()\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Define function to calculate accuracy for both SL and ML tasks\n",
    "def calculate_accuracy(preds, targets, task='sl'): # def calculate_accuracy(preds, targets, task='sl'):\n",
    "#    if task == 'sl':\n",
    "#        predicted_labels = torch.argmax(preds, dim=1)\n",
    "#        correct_predictions = (predicted_labels == targets).sum().item()\n",
    "    if task == 'ml': # elif task == 'ml':\n",
    "        predicted_labels = (preds > 0.5).float()  # Threshold predictions for multi-label task\n",
    "        correct_predictions = (predicted_labels == targets).all(dim=1).sum().item()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid task. It should be 'sl'.\")  # raise ValueError(\"Invalid task. It should be 'sl' or 'ml'.\")\n",
    "\n",
    "    total_samples = targets.size(0)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy\n",
    "\n",
    "def calculate_f1_ml(preds, targets):\n",
    "    predicted_labels = (preds > 0.5).float()\n",
    "\n",
    "    tp = (predicted_labels * targets).sum().item()\n",
    "    fp = ((predicted_labels - targets) == 1).sum().item()\n",
    "    fn = ((predicted_labels - targets) == -1).sum().item()\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    return f1_score\n",
    "\n",
    "# Modify the train_step function to include accuracy calculation and f1 for ML\n",
    "def train_step(model, optimizer, ml_loss_fn, data, device): # def train_step(model, optimizer, sl_loss_fn, ml_loss_fn, data, device):\n",
    "    # Retrieve data\n",
    "    x, ml_y = data # x, sl_y, ml_y = data\n",
    "\n",
    "    # Convert to device\n",
    "    x = x.to(device)\n",
    "#    sl_y = sl_y.to(device)\n",
    "    ml_y = ml_y.to(device)\n",
    "\n",
    "    # Zero out gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    ml_preds = model(x) # sl_preds, ml_preds = model(x)\n",
    "\n",
    "    # Calculate losses\n",
    "#    sl_loss = sl_loss_fn(sl_preds, torch.argmax(sl_y, dim=1))\n",
    "    ml_loss = ml_loss_fn(ml_preds, ml_y)\n",
    "    loss = ml_loss # loss = sl_loss + ml_loss\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Step optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracies\n",
    "#    sl_accuracy = calculate_accuracy(sl_preds, torch.argmax(sl_y, dim=1), task='sl')\n",
    "    ml_accuracy = calculate_accuracy(ml_preds, ml_y, task='ml')\n",
    "\n",
    "    # Calculate F1 scores\n",
    "    ml_f1 = calculate_f1_ml(ml_preds, ml_y)\n",
    "\n",
    "    # Return losses and accuracies\n",
    "    return ml_loss.item(), ml_accuracy, ml_f1 # return sl_loss.item(), ml_loss.item(), sl_accuracy, ml_accuracy, ml_f1\n",
    "\n",
    "# Lists to store losses and accuracies for plotting\n",
    "#train_lossessl = []\n",
    "train_lossesml = []\n",
    "#train_accuraciessl = []\n",
    "train_accuraciesml = []\n",
    "train_f1ml = []\n",
    "\n",
    "for i in tqdm(range(epochs), desc='Epochs'):\n",
    "    print(\"Epoch \", i)\n",
    "#    total_sl_loss = 0.0\n",
    "    total_ml_loss = 0.0\n",
    "#    total_sl_accuracy = 0.0\n",
    "    total_ml_accuracy = 0.0\n",
    "    total_ml_f1 = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    with tqdm(train_loader, desc='Training', total=len(train_loader), miniters=1) as pbar:\n",
    "        for data in pbar:\n",
    "            ML_loss, ML_accuracy, ML_f1 = train_step(model, optimizer, ml_loss_fn, data, device)  # SL_loss, ML_loss, SL_accuracy, ML_accuracy, ML_f1 = train_step(model, optimizer, sl_loss_fn, ml_loss_fn, data, device)\n",
    "\n",
    "#            total_sl_loss += SL_loss\n",
    "            total_ml_loss += ML_loss\n",
    "#            total_sl_accuracy += SL_accuracy\n",
    "            total_ml_accuracy += ML_accuracy\n",
    "            total_ml_f1 += ML_f1\n",
    "            total_batches += 1 #data[0].size(0)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'Total samples': total_batches,\n",
    "#                'SL Loss': total_sl_loss/ total_batches,\n",
    "                'ML Loss': total_ml_loss/ total_batches,\n",
    "#                'SL Accuracy': total_sl_accuracy/ total_batches,\n",
    "                'ML Accuracy': total_ml_accuracy/ total_batches,\n",
    "                'ML F1': total_ml_f1 / total_batches,\n",
    "            })\n",
    "\n",
    "    # Calculate average losses, accuracies and F1 score\n",
    "#    avg_sl_loss = total_sl_loss / len(train_loader)\n",
    "    avg_ml_loss = total_ml_loss / len(train_loader)\n",
    "#    avg_sl_accuracy = total_sl_accuracy / len(train_loader)\n",
    "    avg_ml_accuracy = total_ml_accuracy / len(train_loader)\n",
    "    avg_ml_f1 = total_ml_f1 / len(train_loader)\n",
    "\n",
    "    # Append losses and accuracies to the lists\n",
    "#    train_lossessl.append(avg_sl_loss)\n",
    "    train_lossesml.append(avg_ml_loss)\n",
    "#    train_accuraciessl.append(avg_sl_accuracy)\n",
    "    train_accuraciesml.append(avg_ml_accuracy)\n",
    "    train_f1ml.append(avg_ml_f1)\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "#plt.plot(train_lossessl, label='Train Loss SL')\n",
    "plt.plot(train_lossesml, label='Train Loss ML')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "#plt.plot(train_accuraciessl, label='Train Accuracy SL')\n",
    "plt.plot(train_accuraciesml, label='Train Accuracy ML')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_f1ml, label='Train F1 ML')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1')\n",
    "plt.title('Training F1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Load a test image\n",
    "img_path = '56_1.jpg'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "plt.imshow(img)\n",
    "\n",
    "# Resize image and convert to tensor\n",
    "transform = transforms.Compose([transforms.Resize(IMG_SIZE), transforms.ToTensor()])\n",
    "img = transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "# Get model predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    ml_preds = model(img.to(device)) # sl_preds, ml_preds = model(img.to(device))\n",
    "\n",
    "#sl_preds = torch.nn.functional.softmax(sl_preds)\n",
    "#sl_preds = sl_preds.cpu().numpy()\n",
    "ml_preds = ml_preds.cpu().numpy()\n",
    "\n",
    "# Plot prediction results\n",
    "#sl_preds = sl_preds.squeeze()\n",
    "#plt.figure(figsize=(10, 5))\n",
    "#plt.bar(classes, sl_preds)\n",
    "#plt.title('Softmax Prediction')\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.xlabel('Food Category')\n",
    "#plt.ylabel('Probability')\n",
    "#plt.show()\n",
    "\n",
    "ml_preds = ml_preds.squeeze()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(base_ing, ml_preds)\n",
    "plt.title('Sigmoid Prediction')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Ingredient')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
